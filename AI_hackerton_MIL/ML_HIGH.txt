Hyperparameter tuning

실무적 관점에서 개선 방법을 araboja

batch size, learning rate, optimizer등
grid search보다 random search가 유용쓰

적절한 자동화가 관건이다.


Model Stacking

k fold처럼 test set을 겹치지 않게 여러분 나눈다.

각 fold에 대해 predict한다.

1차 모델의 결과를 2차 모델의 인자로 넣어 여러 모델을 쌓아 사용한다.

이 때 1차모델의 결과가 첫 과정에 의해 전체 데이터와 같아진다. 이걸 넣는것이다.

def category_to_number(x, category_map, feature_name):
	if x[feature_name] in category_map:
		return category_map[x[feature_name]]
	else:
		0

df_test[rank_feature_name] df_test.apply(lambda x: category_to_number(x, category_map, feature_name), axis=1)

np.arange(1461, 1461 + 1459) 하면 a 에서 b까지 수열 만듬

df_processed_test[df_features[-NUM_FEATURES-1:-1].index.tolist]
//전처리된 데이터셋을 중요도순으로 나열


concatenate는 두 행렬을 원하는 방향으로 붙인다. 0,1,2 ... 번째 인자를 기준으로

그래서...

1. 모델1, 모델2에 대한 predict를 각각 구한다.
2. 합친다. 만약 1460, 1이 원래 결과라면 1460,2가 나오거나 한다.
이것이 LEVEL1 model이 된다.

3. 1460, 2를 받는 xgboost model을 만들어 학습시킨다.
이 XGBOOST가 level2모델이다.

Model quntization

시간 최적화
모델 양자화

실 서비스에서 inference time은 중요하다.

데이터를 float 32에서 int8로 변환한다.


1. 이미 학습된 모델을 양자화시킬때

 최대 최소를 1, 0으로 잡고비율맞춰 바꿔주면 된다.
 모델이 작으면 정확도 변화가 매우 커질 수 있다.(outlier의 영향을 많이 받는다.)

2. 학습시키며 양자화시킴

 위의 단점을 해소하기 위함
 pip install -q tensorflow-model-optimization

 
